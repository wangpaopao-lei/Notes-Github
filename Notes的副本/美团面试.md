# 大数据开发

## HDFS

### Q1 架构

块存储

1. NameNode：存储元数据、管理 DataNode
2. DataNode：存储实际的数据块
3. Secondary NameNode：定期合并 fsimage 和 edits

- FsImage：元数据因为要经常进行读写，会存放在内存中，FsImage 是元数据在磁盘上的备份
- edits：存储对元数据的更新操作（顺序写的方式，效率不会太低），一旦重启 NameNode，会首先进行 FsImage 和 edits 的合并，形成最新的元数据
- 如果一直向 edits 写数据，会变得很大，那么恢复元数据就会很卡，因此有了 Secondary NameNode 用来在 NameNode 运行时==定期==进行合并，这样合并就会很快



### Q2 写流程

1. 客户端向 NameNode 请求，NameNode 检查文件是否已经存在，如果不存在，允许客户端上传
2. 客户端再次向 NameNode 请求上传到哪些 DataNode 节点上，NameNode 返回一些节点
3. 客户端向==请求== DataNode1 上传数据，DataNode1 会继续调用 DataNode2，DataNode2 会继续调用 DataNode3，这个流式的通信就建立起来了，紧接着 dn3，dn2，dn1 逐级应答客户端（建立通信）
4. 客户端向 dn1 上传第一个 block，以 packet 为单位（默认 64K），dn1 收到传给 dn2，dn2 传给 dn3
5. 第一个 block 传输完成，客户端再请求上传第二个 block

## MapReduce

mr 流程

数据倾斜

### Q1 流程

1. 分为 map、shuffle、reduce 三个阶段
   1. map：
      1. 通过 InputFormat 把输入目录下的文件进行逻辑切片，默认大小等于 block 大小，每一个切片由一个 maptask 来处理，同时将切片中的数据解析成键值对，k 表示偏移量，v 表示一行内容
      2. 调用 Mapper 类中的 map 方法，将每一行内容进行处理，解析为键值对，在 wordcount 案例中，k 表示单词，v 表示数字
   2. shuffle：map 端的 shuffle 和 reduce 端的 shuffle
      1. 将 map 后的 kv 写入环形缓冲区（默认 100m），一半写元数据（k 的起始位置、v 的起始位置、v的长度、partition 号），一半写 kv 数据，等到达 80%的时候，就要进行 spill 溢写操作，溢写之前要对 k 按照分区进行快速排序，然后写到文件中，并且多个溢写文件进行 merge 归并排序
      2. ==分区==默认算法是 HashPartitioner，分区号是 key 的 hashcode 对 reduce task 个数取模得到的。这时有一个优化方法，combiner 合并，就是使用预聚合操作，将有相同 key 的 value 合并起来，减少溢写到磁盘的数据量，只能用来累加、最大值使用，不能在求平均值时使用
      3. reduce 端的 shuffle 就是 reduce 会拉取同一分区的各个 maptask 结果到内存中，如果放不下，就会溢写到磁盘上，然后对内存和磁盘上的数据进行归并排序
      4. ==merge 的形式==：三种，内存到内存、内存到磁盘、磁盘到磁盘。默认情况下第一种不启用，第二种一直在运行，然后启用第三种方式生成最终的文件
   3. reduce 就是将 key 相同的数据调用一次 reduce 方法，每次调用产生一个键值对，最后将这些键值对写入 HDFS 文件中

## Hive

优化。

常用函数

## YARN



## ZooKeeper



## Flume

使用

## Kafka

分区

## HBase



## Spark



## Flink







# Java



## JVM





## 并发编程







# 计算机基础

## 计网



## OS



## DB

三范式

## DS





# 数仓

分层介绍，dws 层，统计粒度

# SQL



