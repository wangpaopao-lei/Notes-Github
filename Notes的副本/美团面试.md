# 			大数据开发

## 自我介绍

您好，我叫王磊，现就读于北京邮电大学数据科学与大数据技术专业，现在即将大四，我课程学习的不错，专业排名前十五名左右。

今天来面试的岗位是大数据开发工程师，我认为这个岗位主要要求两方面的能力，一个是开发方面的能力，一个是数据应用方面的能力，包括数据仓库、数据挖掘、大数据技术等等。在校期间，我曾作为后端开发负责人参与过大创项目，也曾在实验室进行实习，主要参与图神经网络开源工具包的开发，就是深度学习这一块的内容。



自我介绍加上技能

找公司资料



缺点：缺乏工作经验

为什么要选这个岗位：展现契合度





两个方面：一个开发、一个数据挖掘+深度学习



## HDFS

### Q1 架构

块存储

1. NameNode：存储元数据、管理 DataNode
2. DataNode：存储实际的数据块
3. Secondary NameNode：定期合并 fsimage 和 edits

- FsImage：元数据因为要经常进行读写，会存放在内存中，FsImage 是元数据在磁盘上的备份
- edits：存储对元数据的更新操作（顺序写的方式，效率不会太低），一旦重启 NameNode，会首先进行 FsImage 和 edits 的合并，形成最新的元数据
- 如果一直向 edits 写数据，会变得很大，那么恢复元数据就会很卡，因此有了 Secondary NameNode 用来在 NameNode 运行时==定期==进行合并，这样合并就会很快



### Q2 写流程

1. 客户端向 NameNode 请求，NameNode 检查文件是否已经存在，如果不存在，允许客户端上传
2. 客户端再次向 NameNode 请求上传到哪些 DataNode 节点上，NameNode 返回一些节点
3. 客户端向==请求== DataNode1 上传数据，DataNode1 会继续调用 DataNode2，DataNode2 会继续调用 DataNode3，这个流式的通信就建立起来了，紧接着 dn3，dn2，dn1 逐级应答客户端（建立通信）
4. 客户端向 dn1 上传第一个 block，以 packet 为单位（默认 64K），dn1 收到传给 dn2，dn2 传给 dn3
5. 第一个 block 传输完成，客户端再请求上传第二个 block

## MapReduce

mr 流程

数据倾斜

### Q1 流程

1. 分为 map、shuffle、reduce 三个阶段
   1. map：
      1. 通过 InputFormat 把输入目录下的文件进行逻辑切片，默认大小等于 block 大小，每一个切片由一个 maptask 来处理，同时将切片中的数据解析成键值对，k 表示偏移量，v 表示一行内容
      2. 调用 Mapper 类中的 map 方法，将每一行内容进行处理，解析为键值对，在 wordcount 案例中，k 表示单词，v 表示数字
   2. shuffle：map 端的 shuffle 和 reduce 端的 shuffle
      1. 将 map 后的 kv 写入环形缓冲区（默认 100m），一半写元数据（k 的起始位置、v 的起始位置、v的长度、partition 号），一半写 kv 数据，等到达 80%的时候，就要进行 spill 溢写操作，溢写之前要对 k 按照分区进行快速排序，然后写到文件中，并且多个溢写文件进行 merge 归并排序
      2. ==分区==默认算法是 HashPartitioner，分区号是 key 的 hashcode 对 reduce task 个数取模得到的。这时有一个优化方法，combiner 合并，就是使用预聚合操作，将有相同 key 的 value 合并起来，减少溢写到磁盘的数据量，只能用来累加、最大值使用，不能在求平均值时使用
      3. reduce 端的 shuffle 就是 reduce 会拉取同一分区的各个 maptask 结果到内存中，如果放不下，就会溢写到磁盘上，然后对内存和磁盘上的数据进行归并排序
      4. ==merge 的形式==：三种，内存到内存、内存到磁盘、磁盘到磁盘。默认情况下第一种不启用，第二种一直在运行，然后启用第三种方式生成最终的文件
   3. reduce 就是将 key 相同的数据调用一次 reduce 方法，每次调用产生一个键值对，最后将这些键值对写入 HDFS 文件中

### Q2 wordcount

1. mapper

```java
public class mapper extends Mapper<LongWritable,Text,Text,IntWritable>{

    private Text k = new Text();
    private IntWritable v = new IntWritable(1);
    @Override
    protected void map(LongWritable key,Text value,Mapper<LongWritable,Text,Text,IntWritable>.Context context) throws IOException,InterruptedException{

        String line = value.toString();
        String[] words=line.trim().split("[^a-zA-z]+");
        for(String word : words){
            if(word.length()>){
                k.set(word.toLowerCase();
                context.write(k,v);
            }
        }
    }
}
```

2. reducer

```java
public class reducer extends Reducer<Text,IntWritable,Text,IntWritable>{
    protected void reduce(Text key, Iterable<IntWritable> values,Reducer<Text,IntWritable,Text,IntWritable>.Context context) throws IOException,InterruptedException{
        int sum=0;
        for(IntWritable count:values){
            sum+=count.get();

        }
        context.write(key,new IntWritable(sum));

    }
}

```



## Hive

优化。

常用函数

### Q1 优化手段

1. 建表优化：
   1. 分区表
   2. 分桶表
   3. 合适的文件格式
   4. 合适的压缩格式
2. 语法优化：
   1. 单表查询优化
      1. 列裁剪和分区裁剪
      2. group by 优化
      3. SQL 写成多重模式
   2. 多表查询优化
      1. CBO 优化
      2. 谓词下推
      3. MapJoin
      4. SMB join
3. job 优化
   1. 合理设置 reduce
   2. 推测执行任务整体优化
   3. fetch 抓取
   4. 小数据集启用本地模式
   5. 多个阶段并行执行
   6. JVM 重用：针对小文件过多的时候使用

### Q2 HiveSQL 怎么执行

1. 客户端提交 SQL，Hive 利用 Antlr 框架对 HQL 完成词法语法解析，将 HQL 转化为抽象语法树
2. 遍历 AST，将其转化成 queryblock，可以理解为最小的查询单元
3. 遍历查询块，将其转化为操作树
4. 使用优化器对操作树进行逻辑优化，源码中会遍历所有优化方法，比如 mapjoin、谓词下推等来达到减少 MapReduce job、减少 shuffle 数据量的目的
5. 最后通过执行器将逻辑执行计划转换为物理执行计划（MR 在这就结束了），提交到 Hadoop 运行

### Q3 内部表和外部表的区别

1. 内部表数据由 hive 自身管理，外部表的数据由 HDFS 管理，
2. 删除内部表时，元数据和原始数据都会被删除，而删除外部表时，仅仅会删除元数据不会删除原始数据
3. 使用场景：通常都会建外部表因为一个表通常要多人使用，以免删除了还可以找到数据保证数据安全

## YARN



## ZooKeeper



## Flume

使用

## Kafka

分区

## HBase



## Spark

### Q1 和 MapReduce 的区别



1. MapReduce 需要将上一个阶段的所有分区数据都准备好才能进入下一个阶段，要将中间结果写入磁盘然后读取，导致了频繁的 IO；Spark 得益于 RDD 和 DAG，中间结果能够以 RDD 的形式存放在内存中，大大减少了磁盘 IO
2. MapReduce 在 shuffle 阶段要花费大量时间排序，spark 在 shuffle 时如果选择基于 hash 的计算引擎就不需要排序
3. MapReduce 是多进程模型，每个 task 会运行在一个独立的 JVM 进程中，每次启动都需要重新申请计算资源；而 Spark 是多线程模型，每个 executor 单独运行在一个 JVM 进程中而每个 task 是运行在 executor 中的一个线程

### Q2 部署模式

1. Local：不需要其他任何节点资源就可以在本地执行
2. Standalone：只使用 Spark 自身节点运行的集群模式
3. YARN：Spark 作为计算框架，yarn 作为调度框架



### Q3 stage 怎么划分

对于窄依赖，不会划分，将操作尽量放在同一个 stage 中，可以实现流水线并行计算；对于宽依赖，由于有 shuffle 的存在，只能在父 RDD 处理完后才能开始接下来的操作，也就是说需要划分 stage（从后往前，遇到宽依赖就切割 stage）

###  Q4 容错机制

1. stage 输出失败时，上层调度器 DAGscheduler 会进行重试
2. 计算过程中，某个 task 失败，底层调度器会进行重试
3. 计算过程中，如果部分计算结果丢失，可以根据窄依赖和宽依赖的血统重新恢复计算
4. 如果血统非常长，可以对中间结果做检查点写入磁盘中，如果后续计算结果丢失，就从检查点的 RDD 开始重新计算

### Q5 reduce join 如何执行

1. map 阶段：对来自不同表的数据打标签，然后用连接字段作为 key，其余部分和标签作为 value，最后进行输出
2. shuffle 阶段：根据 key 的值进行 hash，这样就可以将 key 相同的送入一个 reduce 中
3. reduce 阶段：对来自不同表的数据进行 join

### Q6 大数据量如何优化 join

1. 大表 join 小表：map join
2. 大表 join 大表：加盐

### Q7 数据倾斜

1. map 端：每个 map task 处理的文件大小不一致（上游表文件大小不均匀，并且小文件特别多）
   1. 解决：合并小文件，尽量让文件大小保持一致
2. reduce 端：key 分布不均匀+shuffle
   1. 解决：开启 map join



## Flink

### Q1 容错性技术

checkpoint







# Java



## JVM





## 并发编程







# 计算机基础

## 计网

### Q1 OSI 七层

应用、表示、会话、传输、网络、数据链路、物理

### Q2 TCP 三次握手



## OS



## DB

三范式

### Q1 三范式

1. 每列属性都是不可再分的值
2. 在 1NF 的基础上消除部分依赖
3. 在 2NF 的基础上消除传递依赖



## DS





# 数仓

分层介绍，dws 层，统计粒度

# SQL



1. 自我介绍
2. 两段经历，稍微仔细的问了问，主要是我做了什么工作
3. 字节里除了抖音还有哪些地方会用到算法工程师
4. 还有下一轮，会更偏技术
5. 提了建议：
   1. 自我介绍说经历的时候 highlight 用了什么技术
   2. 讲解经历的时候用 STAR 法则重新梳理一下，更细节一点
   3. 去LeetCode刷算法题
   4. 背一些八股
