# 数据挖掘大作业

<center>
  ——THUCNews 新闻数据集文本分类
</center>









<center>
  姓名：王磊
</center>

<center>
  学号：2020211538
</center>

<center>
  班级：2020211538
</center>

<center>
  分组情况：单人完成
</center>





## 目录

[toc]





## 分析数据集说明

官网地址：http://thuctc.thunlp.org/

> THUCNews是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档（2.19 GB），均为UTF-8纯文本格式。

<center>
  注：引用自 THUCnews 官网
</center>



分析数据集来源于 **THUCNews** 中文新闻文本分类数据集，由于原始数据集过于庞大，在开始挖掘之前进行了数据清洗、摘要提取、随机截取了部分数据，并划分为训练集、验证集和测试集存储在 **train.txt** 、**dev.txt** 和 **test.txt** 文件中。

训练集中包含 **180000**（十八万）条数据，验证集和测试集分别包含 **10000**（一万）条数据。

数据集按行划分，每行为一条数据，一条数据分为 **text** 和 **label** 两部分。**text** 部分为一句中文新闻，**labe**l 部分为一个整数（0-9 之间），表示该新闻所属的类别。

所有数据分属于**十个类别**：

1. finance 财经
2. realty 地产
3. stocks 股票
4. education 教育
5. science 科学
6. society 社会
7. politics 政治
8. sports 体育
9. game 游戏
10. entertainment 娱乐



截取自部分训练数据：

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230623161316545.png" alt="image-20230623161316545" style="zoom:33%;" />

<center> fig.1 数据集样例





## 分析目标及流程设计

本次任务为文本十分类任务，需要使用训练集中的十八万条带标签的数据训练模型，然后将其应用在测试集上预测文本所对应的类别，计算recall、f1 score、ROC 等评价指标。

### 数据预处理

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230623200941965.png" alt="image-20230623200941965" style="zoom:50%;" />

<center>
  fig.2 原始数据集概览
</center>



THUCNes 数据集的原始数据是按类别编写的目录里的单个 txt 文本文件，在数据预处理阶段，进行了数据清洗、文本摘要提取，提取了部分数据编写成**train.txt** 、**dev.txt** 和 **test.txt** 作为本次实验的数据集。

随后编写了一个 build_dataset 方法，用于提取文件中的数据，其中实现了单词表的提取（用于后续的深度学习）、数据集的迭代读取（iterater）；在用于经典分类算法的预处理流程中，分别使用了**词袋法、TF-IDF、Word2vec** 三种文本转化为向量的方法；在用于深度学习的预处理流程中，将所有单词编制成一个单词表，将数据表示为一个定长的单词表索引序列。

### 分类算法实现

在经典分类算法实现阶段，调用 scikit-learn 库和 xgboost 库实现了**决策树**、**SVM**、**XGBoost** 三种模型。

在深度学习算法实现阶段，使用 pytorch 编写了 **RNN**、**双向 LSTM** 两种模型。

最后计算各个模型的评价指标，进行了简要的分析。

## 经典分类算法实现

### 数据预处理

在数据预处理阶段，我编写了 build_dataset_ml 函数，用于将词袋法、TF-IDF、word2vec 应用于原始数据供经典算法学习，函数的返回值为一个词典，对应不同预处理方法处理得到的数据

1. 词袋法：调用`sklearn.feature_extraction.text.CountVectorizer`
2. TF-IDF：调用`sklearn.feature_extraction.text.TfidfVectorizer`
3. Word2vec：调用`gensim.models.Word2Vec`

==相关代码如下：==

```Python
def build_dataset_ml(config, use_word):
    if use_word:
        tokenizer = lambda x: x.split(' ')  # 以空格隔开，word-level
    else:
        tokenizer = lambda x: [y for y in x]  # char-level

    import random

    # Load the training data
    with open(config.train_path, 'r', encoding='UTF-8') as f:
        lines = f.readlines()
        selected_indices = random.sample(range(len(lines)), len(lines) //5)  # get 10% of the indices
        train_data = [lines[i].strip().split('\t')[0] for i in selected_indices]
        train_labels = [lines[i].strip().split('\t')[1] for i in selected_indices]

    # Load the testing data
    with open(config.test_path, 'r', encoding='UTF-8') as f:
        lines = f.readlines()
        selected_indices = random.sample(range(len(lines)), len(lines)//5)  # get 10% of the indices
        test_data = [lines[i].strip().split('\t')[0] for i in selected_indices]
        test_labels = [lines[i].strip().split('\t')[1] for i in selected_indices]
    train_labels=np.array(train_labels)
    test_labels = np.array(test_labels)

    # Use Bag of Words to vectorize the texts
    vectorizer_bow = CountVectorizer(tokenizer=tokenizer)
    X_train_bow = vectorizer_bow.fit_transform(train_data)
    X_test_bow = vectorizer_bow.transform(test_data)

    # Use TF-IDF to vectorize the texts
    vectorizer_tfidf = TfidfVectorizer(tokenizer=tokenizer)
    X_train_tfidf = vectorizer_tfidf.fit_transform(train_data)
    X_test_tfidf = vectorizer_tfidf.transform(test_data)

    # Use Word2Vec to vectorize the texts
    # Note: In practice, you might want to use a pretrained Word2Vec model instead of training it on your data.
    w2v_model = Word2Vec([tokenizer(text) for text in train_data], vector_size=100, min_count=1)
    X_train_w2v = np.array([np.mean([w2v_model.wv[w] for w in tokenizer(text)], axis=0) for text in train_data])
    X_test_w2v = np.array([np.mean([w2v_model.wv[w] if w in w2v_model.wv else np.zeros(100) for w in tokenizer(text)], axis=0) for text in test_data])

    return {
        'bow': ((X_train_bow, train_labels), (X_test_bow, test_labels)),
        'tfidf': ((X_train_tfidf, train_labels), (X_test_tfidf, test_labels)),
        'w2v': ((X_train_w2v, train_labels), (X_test_w2v, test_labels))
    }
```



### 模型实现

通过上面的数据预处理，我们已经得到了一组由各种预处理方法得到的数据集，在这个部分，我们迭代上述的数据集，再定义一组机器学习分类模型，通过两层循环，训练并打印相应的结果。

实现了如下模型：

1. SVM：调用自`sklearn.svm`
2. 决策树：调用自`sklearn.tree.DecisionTreeClassifier`
3. XGBoost：调用自`xgboost.XGBClassifier`

==代码如下：==

```python
models = {
        "SVM": svm.SVC(),
        "DecisionTree": DecisionTreeClassifier(),
        "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
    }

    for method, data in dataset.items():
        print(f"Using {method} method:")
        (X_train, y_train), (X_test, y_test) = data
        from sklearn.preprocessing import LabelEncoder
        le = LabelEncoder()
        y_train = le.fit_transform(y_train)
        y_test=le.fit_transform(y_test)
        # print(y_train)
        for model_name, model in models.items():
            print(f"Training {model_name}...")
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
            print(classification_report(y_test, y_pred))
```





## 深度学习模型实现

在深度学习模型这一节中，我对数据进行了向量化处理，随后训练了 RNN 和 Bi_LSTM 两个神经网络模型。

### 数据预处理

对深度学习模型的数据预处理方法明显有别于经典的机器学习模型，这主要由于深度学习模型往往复杂度高非常多，泛化能力更强，因此可以采用包含更多信息的处理方式。本次实验主要进行了以下处理：

1. 设置**词表长度 m** 和**文本向量长度 n**
2. 浏览整个数据文件，提取其中词频排序前 m 的单词构造出 **vocab**（vocabulary 单词表），形成数组索引->对应单词的映射
3. 对文本数据进行分词，将**每个单词替换为其在单词表中的索引**，由此构造出一个整数向量
4. 对于长度不足 n 的向量数据，向其中填充 padding 符号

==相关代码：==

```Python
def build_dataset(config, ues_word):
    if ues_word:
        tokenizer = lambda x: x.split(' ')  # 以空格隔开，word-level
    else:
        tokenizer = lambda x: [y for y in x]  # char-level
    if os.path.exists(config.vocab_path):
        vocab = pkl.load(open(config.vocab_path, 'rb'))
    else:
        vocab = build_vocab(config.train_path, tokenizer=tokenizer, max_size=MAX_VOCAB_SIZE, min_freq=1)
        pkl.dump(vocab, open(config.vocab_path, 'wb'))
    print(f"Vocab size: {len(vocab)}")

    def load_dataset(path, pad_size=32):
        contents = []
        with open(path, 'r', encoding='UTF-8') as f:
            for line in tqdm(f):
                lin = line.strip()
                if not lin:
                    continue
                content, label = lin.split('\t')
                words_line = []
                token = tokenizer(content)
                seq_len = len(token)
                if pad_size:
                    if len(token) < pad_size:
                        token.extend([PAD] * (pad_size - len(token)))
                    else:
                        token = token[:pad_size]
                        seq_len = pad_size
                # word to id
                for word in token:
                    words_line.append(vocab.get(word, vocab.get(UNK)))
                contents.append((words_line, int(label), seq_len))
        return contents  # [([...], 0), ([...], 1), ...]
    train = load_dataset(config.train_path, config.pad_size)
    dev = load_dataset(config.dev_path, config.pad_size)
    test = load_dataset(config.test_path, config.pad_size)
    return vocab, train, dev, test

```



随后实现了 DatasetIterater 类，用于迭代数据集，提取处理完成后的数据，将其转化为张量后传递给模型。

### RNN

使用 pytorch.nn 封装的类构建了 RNN 模型

==模型类如下：==

```Python
class Config(object):

    """配置参数"""
    def __init__(self, dataset, embedding):
        self.model_name = 'TextRNN'
        self.train_path = dataset + '/data/train.txt'                                # 训练集
        self.dev_path = dataset + '/data/dev.txt'                                    # 验证集
        self.test_path = dataset + '/data/test.txt'                                  # 测试集
        self.class_list = [x.strip() for x in open(
            dataset + '/data/class.txt', encoding='utf-8').readlines()]              # 类别名单
        self.vocab_path = dataset + '/data/vocab.pkl'                                # 词表
        self.save_path = dataset + '/saved_dict/' + self.model_name + '.ckpt'        # 模型训练结果
        self.log_path = dataset + '/log/' + self.model_name
        self.embedding_pretrained = torch.tensor(
            np.load(dataset + '/data/' + embedding)["embeddings"].astype('float32'))\
            if embedding != 'random' else None                                       # 预训练词向量
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # 设备

        self.dropout = 0.5                                              # 随机失活
        self.require_improvement = 1000                                 # 若超过1000batch效果还没提升，则提前结束训练
        self.num_classes = len(self.class_list)                         # 类别数
        self.n_vocab = 0                                                # 词表大小，在运行时赋值
        self.num_epochs = 10                                            # epoch数
        self.batch_size = 128                                           # mini-batch大小
        self.pad_size = 32                                              # 每句话处理成的长度(短填长切)
        self.learning_rate = 1e-3                                       # 学习率
        self.embed = self.embedding_pretrained.size(1)\
            if self.embedding_pretrained is not None else 300           # 字向量维度, 若使用了预训练词向量，则维度统一
        self.hidden_size = 128                                          # lstm隐藏层
        self.num_layers = 2                                             # lstm层数


'''Recurrent Neural Network for Text Classification with Multi-Task Learning'''


class Model(nn.Module):
    def __init__(self, config):
        super(Model, self).__init__()
        if config.embedding_pretrained is not None:
            self.embedding = nn.Embedding.from_pretrained(config.embedding_pretrained, freeze=False)
        else:
            self.embedding = nn.Embedding(config.n_vocab, config.embed, padding_idx=config.n_vocab - 1)
        self.lstm = nn.LSTM(config.embed, config.hidden_size, config.num_layers,
                            bidirectional=True, batch_first=True, dropout=config.dropout)
        self.fc = nn.Linear(config.hidden_size * 2, config.num_classes)

    def forward(self, x):
        x, _ = x
        out = self.embedding(x)  # [batch_size, seq_len, embeding]=[128, 32, 300]
        out, _ = self.lstm(out)
        out = self.fc(out[:, -1, :])  # 句子最后时刻的 hidden state
        return out

```



### 双向LSTM

使用 pytorch.nn 封装的类实现 Bi_LSTM 模型

==模型类如下：==

```Python
class Config(object):
    """配置参数"""
    def __init__(self, dataset, embedding):
        self.model_name = 'Bi_LSTM'
        self.train_path = dataset + '/data/train.txt'                                # 训练集
        self.dev_path = dataset + '/data/dev.txt'                                    # 验证集
        self.test_path = dataset + '/data/test.txt'                                  # 测试集
        self.class_list = [x.strip() for x in open(
            dataset + '/data/class.txt', encoding='utf-8').readlines()]              # 类别名单
        self.vocab_path = dataset + '/data/vocab.pkl'                                # 词表
        self.save_path = dataset + '/saved_dict/' + self.model_name + '.ckpt'        # 模型训练结果
        self.log_path = dataset + '/log/' + self.model_name
        self.embedding_pretrained = torch.tensor(
            np.load(dataset + '/data/' + embedding)["embeddings"].astype('float32'))\
            if embedding != 'random' else None                                       # 预训练词向量
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # 设备

        self.dropout = 0.5                                              # 随机失活
        self.require_improvement = 1000                                 # 若超过1000batch效果还没提升，则提前结束训练
        self.num_classes = len(self.class_list)                         # 类别数,二元预测则为2
        self.n_vocab = 0                                                # 词表大小，在运行时赋值
        self.num_epochs = 1                                             # epoch数
        self.batch_size = 128                                           # mini-batch大小
        self.pad_size = 32                                              # 每句话处理成的长度(短填长切)
        self.learning_rate = 1e-3                                       # 学习率
        self.embed = self.embedding_pretrained.size(1)\
            if self.embedding_pretrained is not None else 300           # 字向量维度
        self.hidden_size = 256                                          # 隐藏层维度
        self.num_layers = 2                                             # LSTM层数


class Model(nn.Module):
    def __init__(self, config):
        super(Model, self).__init__()
        if config.embedding_pretrained is not None:
            self.embedding = nn.Embedding.from_pretrained(config.embedding_pretrained, freeze=False)
        else:
            self.embedding = nn.Embedding(config.n_vocab, config.embed, padding_idx=config.n_vocab - 1)
        self.lstm = nn.LSTM(config.embed, config.hidden_size, num_layers=config.num_layers, bidirectional=True, batch_first=True)
        self.dropout = nn.Dropout(config.dropout)
        self.fc = nn.Linear(config.hidden_size * 2, config.num_classes)

    def forward(self, x):
        out = self.embedding(x[0])  # [batch_size, seq_len, embed_size]
        out, _ = self.lstm(out)  # [batch_size, seq_len, hidden_size*2]，由正向和反向LSTM的隐状态拼接而成
        out = out[:, -1, :]  # [batch_size, hidden_size*2]，转化为一个2D张量，保留最后一个时间步的输出
        out = self.dropout(out)  # [batch_size, hidden_size*2]，防止过拟合
        out = self.fc(out)  # [batch_size, num_classes]
        return out

```



### 模型训练

在训练环节，我使用了 Adam 优化器、交叉熵损失函数进行训练，并打印中间结果，在一开始的训练过程中，随着训练轮数上升，模型在训练集上的表现越来越好，在验证集上的表现却隐隐下降。

添加了如下方法以加强学习效果并对抗过拟合：

1. 添加随机失活（dropout）
2. 使用 early-stopping 方法，当训练超过 1000batch 仍没有效果提升时则提前结束训练，并且会保存当前得分最高的模型参数

==训练函数如下：==

```Python
def train(config, model, train_iter, dev_iter, test_iter):

    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    device = torch.device(device)

    start_time = time.time()
    model.train()
    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)
    optimizer=optimizer
    # 学习率指数衰减，每次epoch：学习率 = gamma * 学习率
    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
    total_batch = 0  # 记录进行到多少batch
    dev_best_loss = float('inf')
    last_improve = 0  # 记录上次验证集loss下降的batch数
    flag = False  # 记录是否很久没有效果提升
    writer = SummaryWriter(log_dir=config.log_path + '/' + time.strftime('%m-%d_%H.%M', time.localtime()))
    for epoch in range(config.num_epochs):
        print('Epoch [{}/{}]'.format(epoch + 1, config.num_epochs))
        # scheduler.step() # 学习率衰减
        for i, (trains, labels) in enumerate(train_iter):
            outputs = model(trains)
            model.zero_grad()
            loss = F.cross_entropy(outputs, labels)
            loss.backward()
            optimizer.step()
            if total_batch % 100 == 0:
                # 每多少轮输出在训练集和验证集上的效果
                true = labels.data.cpu()
                predic = torch.max(outputs.data, 1)[1].cpu()
                train_acc = metrics.accuracy_score(true, predic)
                dev_acc, dev_loss = evaluate(config, model, dev_iter)
                if dev_loss < dev_best_loss:
                    dev_best_loss = dev_loss
                    torch.save(model.state_dict(), config.save_path)
                    improve = '*'
                    last_improve = total_batch
                else:
                    improve = ''
                time_dif = get_time_dif(start_time)
                msg = 'Iter: {0:>6},  Train Loss: {1:>5.2},  Train Acc: {2:>6.2%},  Val Loss: {3:>5.2},  Val Acc: {' \
                      '4:>6.2%},  Time: {5} {6} '
                print(msg.format(total_batch, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve))
                writer.add_scalar("loss/train", loss.item(), total_batch)
                writer.add_scalar("loss/dev", dev_loss, total_batch)
                writer.add_scalar("acc/train", train_acc, total_batch)
                writer.add_scalar("acc/dev", dev_acc, total_batch)
                model.train()
            total_batch += 1
            if total_batch - last_improve > config.require_improvement:
                # 验证集loss超过1000batch没下降，结束训练
                print("No optimization for a long time, auto-stopping...")
                flag = True
                break
        if flag:
            break
    writer.close()
    test(config, model, test_iter)
```

### 训练输出



<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230623195320196.png" alt="image-20230623195320196" style="zoom: 33%;" />

<center>
  fig.3 RNN 训练结果
</center>



<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230623195532258.png" alt="image-20230623195532258" style="zoom: 33%;" />

<center>
  fig.4 双向 LSTM 训练结果
</center>



## 结果分析

### 经典机器学习模型



#### 词袋预处理

|           | 决策树 | SVM  | XGBoost |
| --------- | ------ | ---- | ------- |
| Accurancy | 0.7    | 0.86 | 0.85    |
| Recall    | 0.7    | 0.86 | 0.85    |
| F1 score  | 0.7    | 0.86 | 0.85    |

<center>
  table.1 词袋法——经典机器学习模型
</center>

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230623234918247.png" alt="image-20230623234918247" style="zoom:50%;" />

<center>
  fig.5 词袋预处理结果对比
</center>





#### TF-IDF预处理

|           | 决策树 | SVM  | XGBoost |
| --------- | ------ | ---- | ------- |
| Accurancy | 0.68   | 0.87 | 0.85    |
| Recall    | 0.67   | 0.87 | 0.85    |
| F1 score  | 0.67   | 0.87 | 0.85    |

<center>
  table.2 TF-IDF——经典机器学习模型
</center>



<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230623234955742.png" alt="image-20230623234955742" style="zoom:50%;" />

<center>
  fig.6 TF-IDF 预处理结果对比
</center>



#### word2vec预处理

|           | 决策树 | SVM  | XGBoost |
| --------- | ------ | ---- | ------- |
| Accurancy | 0.58   | 0.81 | 0.79    |
| Recall    | 0.57   | 0.81 | 0.79    |
| F1 score  | 0.57   | 0.81 | 0.79    |

<center>
  table.3 word2vec——经典机器学习模型
</center>



<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230623235013808.png" alt="image-20230623235013808" style="zoom:50%;" />

<center>
  fig.7 word2vec 预处理结果对比
</center>

三组实验的结果都大致相同：决策树模型的分类效果最差，SVM 的分类效果略微优于 xgboost。

这与猜想的结果不太一样，Xgboost 由于其集成模型的特性，泛化能力和抗过拟合能力都应该由于其他两个模型。猜测产生这样的结果可能是因为在构造 xgboost 分类器时没有经过细致的调参，参数都是使用的默认参数。

在本次实验中，词袋法和 TF-IDF 方法处理的结果差别不大，而 word2vec 的结果明显劣于前两种方法，关于这一问题的探讨我们留到最后一节问题分析中。





### 深度学习模型

|           | RNN    | Bi_LSTM |
| --------- | ------ | ------- |
| Accurancy | 0.8856 | 0.9043  |
| Recall    | 0.8837 | 0.9032  |
| F1 score  | 0.8839 | 0.9035  |

<center>
  table.4 深度学习模型结果对比
</center>

在本次实验中，Bi_LSTM 模型的效果优于 RNN 模型，这也部分印证了双向 LSTM 对上下文依赖信息的学习能力，尤其是双向 LSTM 模型相较于传统的 LSTM 能同时学习前向和后向的隐藏状态，这对于文本分类任务的提升是很大的。

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230623195539269.png" alt="image-20230623195539269" style="zoom:50%;" />

<center>
  fig.8 RNN ROC曲线
</center>



<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230623195217606.png" alt="image-20230623195217606" style="zoom:50%;" />

<center>
  fig.9 Bi_LSTM ROC曲线
</center>



## 问题分析及思考

*Q：要求的评价指标里包含 ROC 曲线，为何我最后的报告里并没有这项指标？*

**A：ROC 曲线的计算需要用到模型输出的每个类别的概率，在我选取的经典分类算法中，决策树和 SVM 两种模型是不支持概率预测的，想要计算 ROC 曲线需要使用决策函数等其他方法，索性就都没有计算这个指标，最终使用了准确率、召回率、F1 分数三个指标。**

*Q：word2vec 预处理后的训练结果无论哪个模型均弱于其他两种方法，是因为这种方法本身较弱吗？*

**A：应该不是，我推测有两个可能原因：**

1. **基于 sklearn 的机器学习模型的训练不能使用 GPU 加速，经典分类算法在大规模数据集上会训练的非常慢，因此我只随机选取了数据集的 1/3 进行训练。word2vec 本身是一个模型，在 word2vec 的词向量长度为 100，导致没有足够的数据学习单词的表达，由此可能导致 word2vec 模型的效果较差。**
2. **对 word2vec 模型没有经过像深度学习模型那样细致的调参，大部分地方使用的默认参数，这样可能导致在本数据集上的效果较差。**

*Q：在深度学习模型的输出里，指标的加权平均值和算术平均值完全一样，这是否有点问题？*

**A：这是由于在数据集中各个类别的样本数量是完全一样的，即数据集在各个类别上是均匀分布的。**