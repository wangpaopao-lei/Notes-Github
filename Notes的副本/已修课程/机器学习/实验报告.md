## 目录

---

[toc]





## 问题分析

---

本次大作业是一个图象三分类任务，根据不同天气条件下的道路图片对天气进行预测三种天气情况分别对应的标签如下：

| dry  |  0   |
| :--: | :--: |
| snow |  1   |
| ice  |  2   |

 图像分类是计算机视觉的重要研究领域，卷积神经网络在这一领域大获成功，如今流行的图像分类模型绝大多数都是卷积神经网络及其变种。

本次任务给出了如下结构的数据集，在训练集中，各个类别的数据都已分类。

```shell
./data
├── basic_data
│  		├── dry
│  		├── ice
│  		└── snow
└── pred_data
```





## 文件结构说明

---

文件结构如下

```shell
./
├── A.xlsx
├── __pycache__
├── class_indices.json
├── model.py
├── my_dataset.py
├── pre_efficientnetv2-s.pth
├── predict.py
├── runs
├── train.py
├── trans_effv2_weights.py
├── utils.py
└── weights
```

- A.xlsx：预测结果输出
- class_indices.json：存储 label 对应的索引，由train.py文件自动生成
- model.py：efficientnetv2模型主体部分，其中封装了 droppath、卷积层、SE 机制、MBConv 层、FusedMBConv 类
- my_dataset.py：自定义数据集，继承自 Dataset 类，实现了 len、getitem 方法
- pre_efficientnetv2-s.pth：模型预训练权值
- predict.py：预测脚本
- runs：存储日志文件
- train.py：训练脚本
- Utils.py：工具库，实现了数据集读取、单词 epoch 训练、模型评估等方法
- weights：存放已经训练完成的模型参数





## 实验环境

---

- IDE：PyCharm 2021.3.3 (Professional Edition)
- Python解释器：Python 3.9
- 主要外部库：
  - pytorch 1.13.1               
  - torchvision 0.13.1 





## 数据预处理

---

由于数据集图象格式统一为 240×360，因此在数据预处理部分，==**只需重点关注其在模型训练过程中起到的数据增强作用以提升模型泛化性能和应对过拟合**==

![image-20230214230551832](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230214230551832.png)



采用了如下数据处理策略

```python
data_transform = {
        "train":
  transforms.Compose([transforms.RandomResizedCrop(img_size[num_model][0]),
                    transforms.RandomHorizontalFlip(),
                    transforms.ToTensor(),
                    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])]),
        "val": 
  transforms.Compose([transforms.Resize(img_size[num_model][1]),
                    transforms.CenterCrop(img_size[num_model][1]),
                    transforms.ToTensor(),
                    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])}
```

### 训练集 train

1. `transforms.RandomHorizontalFlip()`：以 0.5 的概率水平翻转图象
2. `transforms.ToTensor()`：转化为 tensor
3. `transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])`：对 tensor 图片进行规范化处理

### 验证集 val

1. `transforms.CenterCrop(img_size[num_model][1]`：在图片中心区域进行裁剪
2. `transforms.ToTensor()`：转化为 tensor
3. `transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])`：对 tensor 图片进行规范化处理

### 测试集 predict

```python
data_transform = transforms.Compose(
        [transforms.Resize(img_size[num_model][1]),
         transforms.CenterCrop(img_size[num_model][1]),
         transforms.ToTensor(),
         transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])
```

与验证集的操作相同





## 模型设计

---

在基本确定使用 CNN 的前提下，模型的设计主要关注以下几点：

1. 数据集规模：本次训练用数据集包含 9480 张图片，测试集包含 100 张图片，因此在模型选择上不宜过复杂，否则训练时间和过拟合的概率都会上升
2. 模型主体架构：尽量参照已有的优秀模型，达到事半功倍的效果
3. 新兴方法的使用：课本上学习的内容和网络上大部分资料都讲述的是经典模型，这也意味着老旧，关注近几年的一些创新理论和方法来优化模型

基于以上几点考虑，我将目光放在了 2021 年的文章《EfficientNetV2: Smaller Models and Faster Training》上。

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215025307650.png" alt="image-20230215025307650" style="zoom:67%;" />

### 概要和思路

#### EfficientNetV2

> our experiments show that EfficientNetV2 models train much faster than state-of-the-art models while > being up to 6.8x smaller.
>
> 原文中这样写到，EfficientNetV2主要提出了以下方法来强化其性能：
>
> 1. **progressive learning 渐进学习方法**：根据训练图象的尺寸动态调节正则化方法（如 dropout、data augmentation 和 mixup），这一方法不仅提升训练速度还能提升准确性
> 2. **Fused-MBConv 模块：**模型卷积层的设计<img src="https://img-blog.csdnimg.cn/20210519181235595.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTQxMDk3,size_16,color_FFFFFF,t_70#pic_center" alt="Fused-MBConv" style="zoom:50%;" />
> 3. **SqueezeExcite 模块**：添加了注意力机制
> 4. **NAS 搜索**：选用 NAS 搜索参数

#### 迁移学习

由于模型过大，从头开始训练不仅浪费时间而且效果可能还不尽人意，因此我使用EfficientNetV2_s 模型在 ImageNet 上预训练的参数进行迁移学习，主要分以下步骤

1. 下载预训练参数，载入模型
2. 通过自定义数据集训练网络的最后一个1×1卷积&池化&全连接层
3. 每次迭代保存模型参数，多次迭代后选择合适的模型参数进行预测



### 详细设计

网络结构如图所示

| Stage |      Operator       | Stride | Channels | Layers |
| :---: | :-----------------: | :----: | :------: | :----: |
|   0   |       Conv3x3       |   2    |    24    |   1    |
|   1   | Fused-MBConv1,k3x3  |   1    |    24    |   2    |
|   2   | Fused-MBConv4,k3x3  |   2    |    48    |   4    |
|   3   | Fused-MBConv4,k3x3  |   2    |    64    |   4    |
|   4   | MBConv4,k3x3,SE0.25 |   2    |   128    |   6    |
|   5   | MBConv6,k3x3,SE0.25 |   1    |   160    |   9    |
|   6   | MBConv6,k3x3,SE0.25 |   2    |   256    |   15   |
|   7   | Conv1x1&Pooling&FC  |   -    |   1280   |   1    |

***实现过程中有以下要点***

#### ConvBNAct 类

==大多数情况下，卷积、batch normalization 和激活都是同时出现的，因此编写这个类将卷积层做模块化处理==

```python
class ConvBNAct(nn.Module):
    def __init__(self,
                 in_planes: int,
                 out_planes: int,
                 kernel_size: int = 3,
                 stride: int = 1,
                 groups: int = 1,
                 norm_layer: Optional[Callable[..., nn.Module]] = None,
                 activation_layer: Optional[Callable[..., nn.Module]] = None):
        super(ConvBNAct, self).__init__()

        padding = (kernel_size - 1) // 2
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if activation_layer is None:
            activation_layer = nn.SiLU  # alias Swish  (torch>=1.7)

        self.conv = nn.Conv2d(in_channels=in_planes,
                              out_channels=out_planes,
                              kernel_size=kernel_size,
                              stride=stride,
                              padding=padding,
                              groups=groups,
                              bias=False)

        self.bn = norm_layer(out_planes)
        self.act = activation_layer()

    def forward(self, x):
        result = self.conv(x)
        result = self.bn(result)
        result = self.act(result)

        return result

```



#### Fused-MBConv层

其中 Fused-MBConv 层参照论文源码实现





## 模型训练与评估

---

### 训练脚本 train.py

```python
if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--num_classes', type=int, default=3)
    parser.add_argument('--epochs', type=int, default=30)
    parser.add_argument('--batch-size', type=int, default=8)
    parser.add_argument('--lr', type=float, default=0.01)
    parser.add_argument('--lrf', type=float, default=0.01)
    parser.add_argument('--data-path', type=str,
                        default="/Users/wangpaopaopao/Documents/大数据机器学习/缓考大作业/data/basic_data")
    parser.add_argument('--weights', type=str, default='./weights/model-9.pth',
                        help='initial weights path')
    parser.add_argument('--freeze-layers', type=bool, default=True)
    parser.add_argument('--device', default='cuda:0', help='device id (i.e. 0 or 0,1 or cpu)')

    opt = parser.parse_args()

    main(opt)
```

该程序用于完成对模型的训练，在 main 函数中，**设置了以下命令行参数**

- Num_classes：分类类别数
- epochs
- Batch-size
- lr：学习率
- Data-path：数据集根目录
- weights：预训练权重
- Freeze-layers：是否冻结参数，只学习最后的 head 层
- Device：是否使用 GPU 加速

### 单次训练过程

**由 train_one_epoch 函数实现，该函数有以下要点：**

- 选择==交叉熵==作为损失函数，==准确率==作为评价指标

- 采用 SGD（随机梯度下降）求解参数

- 及时输出结果

==代码如下==

```python
def train_one_epoch(model, optimizer, data_loader, device, epoch):
    model.train()
    loss_function = torch.nn.CrossEntropyLoss()
    accu_loss = torch.zeros(1).to(device)  # 累计损失
    accu_num = torch.zeros(1).to(device)   # 累计预测正确的样本数
    optimizer.zero_grad()

    sample_num = 0
    data_loader = tqdm(data_loader, file=sys.stdout)
    for step, data in enumerate(data_loader):
        images, labels = data
        sample_num += images.shape[0]

        pred = model(images.to(device))
        pred_classes = torch.max(pred, dim=1)[1]
        accu_num += torch.eq(pred_classes, labels.to(device)).sum()

        loss = loss_function(pred, labels.to(device))
        loss.backward()
        accu_loss += loss.detach()

        data_loader.desc = "[train epoch {}] loss: {:.3f}, acc: {:.3f}".format(epoch,
                                                                               accu_loss.item() / (step + 1),
                                                                               accu_num.item() / sample_num)

        if not torch.isfinite(loss):
            print('WARNING: non-finite loss, ending training ', loss)
            sys.exit(1)

        optimizer.step()
        optimizer.zero_grad()

    return accu_loss.item() / (step + 1), accu_num.item() / sample_num
```

### 运行截图

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030719761.png" alt="image-20230215030719761" style="zoom:67%;" />

![image-20230215030730905](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030730905.png)

![image-20230215030742532](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030742532.png)

![image-20230215030754813](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030754813.png)

![image-20230215030805552](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030805552.png)

![image-20230215030820174](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030820174.png)

![image-20230215030831169](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030831169.png)

![image-20230215030841597](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030841597.png)

![image-20230215030850967](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030850967.png)

![image-20230215030900225](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030900225.png)

![image-20230215030908957](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030908957.png)

![image-20230215030918315](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030918315.png)

![image-20230215030926478](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030926478.png)

![image-20230215030935983](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030935983.png)

![image-20230215030955260](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215030955260.png)

![image-20230215031005339](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215031005339.png)

![image-20230215031013674](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215031013674.png)

![image-20230215031022796](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215031022796.png)

![image-20230215031032003](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215031032003.png)

![image-20230215031040914](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215031040914.png)

![image-20230215031051267](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215031051267.png)





## 模型测试结果输出

---

### 预测脚本 predict.py

依次完成以下功能：

1. 读取测试数据，进行数据预处理
2. 通过 softmax 输出分类概率结果
3. 根据需求将结果导入文件或打印在终端

### 遇到的问题

- 生成的  JSON 文件中 label 的索引与题目要求不同

  ![image-20230215040434195](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230215040434195.png)

- 解决方法：正常导出预测数据，在 Excel 中进行替换操作





## 实验小结

---

本次大作业共花费两天两夜共约 30 小时时间，主要时间花在设计模型和训练模型上。

### 感想

- 本次的大作业我完成了数据预处理、模型代码编写、针对任务调整训练方式，最后输出预测结果的全过程。在这一过程中我加深了对机器学习任务过程方法论的理解，深化了对 CNN 等方法的认识，学习到了一些前沿方法和理论并最终用作实践，受益匪浅。

### 遗憾

- 由于选择的模型参数过多，即使后来采取了迁移学习的方法进行补救，同时受限于我的电脑不能使用 GPU 加速，一轮对最后一层参数的训练还是要花费 30 分钟左右的时间。也导致了最后没有时间调整模型和检查小错误，leapboard 得分非常惨淡。

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20220503231232854.png" alt="image-20220503231232854" style="zoom:50%;" />