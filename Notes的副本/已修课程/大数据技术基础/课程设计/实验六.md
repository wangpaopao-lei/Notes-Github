## 实验描述

---

本实验在Hadoop集群的基础上，使用HDFS存储文件数据，并使用MapReduce框架编写代码 实现文件内容合并、去重与排序任务

1. 启动环境
2. 上传文件
3. 新建 Maven 项目
4. 打包并上传项目
5. 执行 MapReduce 程序
6. 查看执行结果



## 实验步骤

----

1. 启动环境

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20221205125934681.png" alt="image-20221205125934681" style="zoom:25%;" />

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20221205125951147.png" alt="image-20221205125951147" style="zoom:25%;" />

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20221205130005845.png" alt="image-20221205130005845" style="zoom:25%;" />

2. 上传文件

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20221205130119821.png" alt="image-20221205130119821" style="zoom:25%;" />

3. 新建 maven 项目

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20221205130333059.png" alt="image-20221205130333059" style="zoom:25%;" />

4. 打包并上传项目

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20221205142734881.png" alt="image-20221205142734881" style="zoom: 25%;" />

5. 执行 MapReduce 程序

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20221205163448015.png" alt="image-20221205163448015" style="zoom:25%;" />

6. 查看执行结果

<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20221205163503784.png" alt="image-20221205163503784" style="zoom:25%;" />



<img src="https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20221205143349395.png" alt="image-20221205143349395" style="zoom:25%;" />