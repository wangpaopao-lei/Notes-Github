##  contents

[toc]

# 列簇式数据库

![image-20230515205612506](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230515205612506.png)

## 概述

Cassandra：AP 特性，数据类型非常丰富

HBASE：CP 特性，数据类型简单，每个值是一个未经解释的字符串



Cassandra 特点：

1. 没有单点故障：去中心化环形存储，对等关系
2. 提供丰富数据类型
3. 提供灵活的查询语言：CQL
4. 支持物化视图
5. 快速写入：写入性能非常高，支持负载均衡策略
6. 读写一致性级别可配置

## 列簇数据存储逻辑架构

![image-20230520152353247](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230520152353247.png)

1. 键空间：相当于数据库
2. 列簇 column family：相当于表，但比表更稀疏
3. 行 row：表示一个数据对象，一行数据具有相同的行键
4. 列：相当于属性，可以存储几个不同时间戳的值

![image-20230521133812018](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230521133812018.png)

1. 键空间
   - 最外层容器
   - 两个配置：
     - 副本放置策略 class：副本放置在 DC 中的策略
       - 简单策略：一个数据中心
       - 网络拓扑策略：多个数据中心，必须为每个数据中心配置复制因子
     - 复制因子 replication_factor：放置在不同节点上的数据的副本数
   - 至少两个复制因子能很好的避免单点故障
   - 综合考虑存储成本，复制因子一般设置为 3
2. 列族
   - 行集合的容器
3. 列
   - 基本数据结构
   - 三元组：列名称、值、时间戳
4. 键
   - 也叫行键，唯一标识
   - 数据存储是按行键排列的，可以对行键定义类型
5. 静态列
   - 用于存储需要在集群不同节点分区中共享的数据列
   - 所有值均为最后一次更改后的值，同一个 username 的两个静态列内容相同
   - 静态列相当于把两张表进行了 join 操作
   - 不能是主键的组成部分

### 关键概念区分

- 主键 primary key
  - 可以是一个列或多个列
- 分区键 partition key
  - 主键的第一列或几个列的组合
  - 主键的一部分，每行数据都需要有
  - 作为一致哈希算法的参数，==将数据分散到集群的不同节点上==
  - 可以由多列构成，用括号括起来即可
- 聚类键 clustering key
  - 决定相同 partition key 数据在分区内的顺序，默认为升序

### Cassandra 模型设计

1. 领域业务实体关系模型设计
2. 领域业务数据查询需求梳理，定义查询，引入冗余，提高数据查询性能
3. 查询需求驱动，逻辑模型设计，触笔定义列族、键等信息
4. 物理模型设计，明确列族名称、列数据类型、键等
5. 模型验证
6. 使用 CQL 定义列族
7. 根据需求变化迭代优化



## 列簇数据库集群架构

1. 主从式集群：
   1. 每个从节点有唯一主节点
   2. 会出现单点故障
   3. HBASE
2. 对等式集群：
   1. 节点地位对等
   2. 不会出现单点故障
   3. Cassandra

### Cassandra 对等集群

基于 Amazon Dynamo 对等模式，采用一致性哈希拓扑划分策略进行读写负载均衡，集群中存储多个副本分布到各个节点上

- 在后台采用 Gossip 协议，运行节点相互通信并检测集群中的任何故障节点
- 节点之间使用数据复制机制，以确保没有单点故障

![image-20230522134042798](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230522134042798.png)

#### 关键组件

1. CommitLog：崩溃回复机制
   - 每个写操作都会写入提交日志，用来重构 MemTable 中的内容
   - CommitLog是 server 级别，每一个节点上的 CommitLog 都统一管理
   - 每个 CommitLog 大小是固定的，成为一个 CommitLogSegment，一般是 128MB
   - **写操作写完 CommitLog 后会在写 MemTable，当一个文件写满后，会新建一个 CommitLog 文件**
   - **当一个 CommitLog 文件对应的所有 CF 对应的 MemTable 都写到磁盘后，会自动清除此类日志文件**
2. MemTable：内存结构
   - 每一个 CF 对应一个 MemTable
   - 内容按 key 排序
   - 缓存回写机制
   - **满足一定要求后批量刷新到磁盘上，存储为 SSTable**
   - 下一次 MemTable 需要刷新一个新的 SSTable 文件中
   - ==将随机 IO 变为顺序 IO 写，降低大量的写操作对于存储系统的压力==
   - 可以认为只有顺序写，没有随机写操作
3. SSTable：存储在磁盘
   - 按照 key 排序后存储键值字符串
   - 一旦写入就不可变更
   - **定期将多个 SSTable 合并成一个 SSTable，称之为压紧或压缩 Compaction**
     1. Merge Keys
     2. combine columns
     3. 合并排序

#### 写流程

![image-20230522135837837](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230522135837837.png)

##### 客户端视角

1. 假设副本数为 n
2. 写操作从客户端发送给集群的任何一个节点，该节点作为这次写操作的代理 Coordinator
3. 哈希分区器根据键计算对应的 n 个副本几点
4. 代理节点将写请求发送给这 n 个节点
5. 根据一致性级别要求确定需要等待写成功的节点个数
6. 代理节点等待着 n 个节点中的某些节点的写响应，满足个数时，将写成功的消息返回客户端

##### 集群视角

1. n 个节点收到写请求后，做两个操作
   1. 追加 CommitLog
   2. 更新 MemTable
2. 写操作快的原因：
   1. 写内存
   2. 慢的部分仅仅是写日志
3. 后台有一些异步的时间可能发生
   1. MemTable 到阈值后可能要被 flush 到 SSTable
   2. 同一个 CF 的多个 SSTable 被合并成一个大的 SSTable

#### 读过程

![image-20230522143059425](https://wangleidetuchuang.oss-cn-beijing.aliyuncs.com/img/image-20230522143059425.png)

1. 假设副本个数 n
2. 读请求从客户端发给一个节点，该节点作为代理，根据读一致性级别配置，确定满足读一致性需求的节点个数 k，并发送请求给这 k 个节点，并返回 k 个点中的最新数据
3. 对于每个收到读请求的节点
   1. 读取 MemTable
   2. 扫描 SSTable
4. 读一致性级别
   1. One：返回第一个响应的节点上面的数据，不保证数据是最新的
   2. Quorum：查询所有节点，返回至少 Replication_Factor/2+1个节中的最新数据
   3. All：查询所有节点，返回所有节点中的最新数据，一个节点失效将导致读失败

### 分区策略

1. 范围分区
2. 哈希分区



一致性哈希算法

为了避免物理节点较少时引起的一致性哈希算法数据倾斜问题，引入虚拟节点概念：**一个物理节点可以对应多个虚拟节点**



分区键的选择：

1. 分区键要有足够的分区键值，以便在集群所有节点之间能均匀的分布数据，典型的分区键是用户 ID、设备 ID 等
2. 业务分析操作，最好单个分区能涵盖一次读所想拿到的数据
3. 分区不要太大



### 持久化管理

Cassandra 支持行级别的原子性和隔离性

- 原子性：**写操作提供分区级别的原子性**，即同一分区的两行或多行写入或更新可以被当做一个原子写入管理操作
- 隔离性：**写操作是完全行级别的隔离性**，单个节点上的一个分区，对客户端来说一次只能写入一行。这个操作范围是严格受限的，直到操作完成
- 持久化：**写操作是持久化的**，由 CommitLog 和 SSTable 保证的持久化



## 列族式数据库应用

