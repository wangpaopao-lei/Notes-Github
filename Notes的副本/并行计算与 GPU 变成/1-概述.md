## contents

[toc]



# 概述



## 应用范式

1. 稠密线性代数
   - 密集矩阵或向量
   - 分为三级：向量-向量，矩阵-向量，矩阵-矩阵
   - 传统科学计算的核心计算模式
2. 稀疏线性代数
   - 包含许多零值
   - 数据通常存储在压缩矩阵中，如 BCSR。
   - 由于压缩的格式，通常是用索引加载和存储来访问的
3. 谱方法
   - 求解偏微分方程的数值方法
4. 多体方法
   - 基于许多离散点之间的相互作用
5. 结构网格
6. 非结构网格
7. MapReduce
8. 。
9. 图遍历：访存操作和存储开销成为关键
10. 动态规划
11. 回溯与分支限界法
12. 图模型
13. 有限状态机

## 并行计算模型



### 三个角度

并行计算模型的提出

1. 理论计算模型
2. 从应用角度看
   1. 数据并行
   2. 任务并行
   3. 隐式并行
3. 体系结构（并行硬件）
   1. 共享内存
   2. 分布式内存
   3. 消息传递

####  理论计算

1. 图灵机
2. 随机存取机（RAM机）
3. PRAM 并行RAM 机：
   1. GPU 就属于这种模型；	
   2. 单指令流多数据流；
   3. 假设有一个容量大小没有限制的共享存储器，并且有多个功能相同的处理器
   4. 分为 EREW，CREW，CRCW，C 表示允许并发，E 表示排斥并发
4. LogP 模型
   1. Latency 延迟
   2. Overhead：间隔
   3. Gap：处理器连续两次发送或接受消息的间隔
   4. Processor：处理器数目
5. BSP 模型
   1. 整体同步并行计算模型
   2. 设立一组串行的 supersteps 超步
   3. 每个超步中的所有进程是并行的
6. Actor 模型
   1. 数据+行为+消息
   2. 一个 Actor 是一个基本计算单元，接收消息，基于消息做一些计算
   3. 消息异步发送给 Actor，Actor 顺序处理收到的消息
   4. “一切皆是演员”

#### 应用角度

- 数据并行
  - 将数据划分为不相交的分区
  - SIMD，SIMT
- 任务并行
  - 重点是进程，或执行线程，它们==在行为上不同==（区分于数据并行），强调对通信的需求
  - MIMD，MPMD，MISD
- 隐式并行
  - 不向编程者透露任何编译器、运行时系统或硬件负责的事情
  - 进程交互对编程者不可见

## 并行硬件

### 并行硬件角度

- 共享内存
  - 进程间传递数据的高效方式
  - 多核处理器直接支持共享内存
- 分布式内存
  - 多处理器系统，每个处理器都有自己私有的内存，计算任务只能在本地数据上运算
- 消息传递
  - 并行进程通过消息传递交换数据，可以是异步的或同步的

##### 并行架构分类

Flynn 分类法

SISD，SIMD，MISD，MIMD。I 表示指令流，D 表示数据流，S 表示 single，M 表示 multiple

##### 硬件并行技术途径

- 单 CPU
  - 指令级并行：已经基本饱和
  - 线程级并行
  - 存储级并行：处理器以重叠的方式并行执行多个因 Cache 失效导致的外部访存的能力（揭示了长外部访存延迟隐藏技术的关键）
  - 区别于 GPU：GPU 采用海量线程来访问数据
- 多 CPU
  - 向量处理机 PVP：有很多处理器，通过共享内存，
  - 对称多处理机 SMP：通常接触的服务器，多个微处理器经由高速总线连向共享存储器
  - 大规模并行处理机 MPP：采用高通信带宽和低延迟的互联网络
  - 工作站机群 COW：单节点也能运行
  
  

主要关注：

1. 地址空间
2. 访存模型
3. 通信机制
4. 互联网络



## 并行编程语言

按存储模型进行分类

- 共享内存
- 分布式内存
- 共享分布式内存



- 协调语言：以通信为核心的方式
- 数据流编程：如 TensorFlow



## CUDA

计算平台，编程模型

CUDA-c

1. cuda driver：比较底层，可以跟系统打交道
2. cuda runtime：
3. cuda library